{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eaedk/Machine-Learning-Tutorials/blob/main/DataAnalysis_Step_By_Step_Guide.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW3v1-2n3CzK"
      },
      "source": [
        "# Intro\n",
        "## General\n",
        "\"Data analysis is a process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making.\" ([Wikipedia](https://en.wikipedia.org/wiki/Data_analysis)).\n",
        "\n",
        "In Data Analysis, there are some analysis paradigms : **Univariate, Bivariate, Multivariate**. We apply these paradigms to analyze the features (or statistical variables, or columns of the dataframe) of the dataset and to have a better understanding.\n",
        "\n",
        "**Numeric features** are features with numbers that you can perform mathematical operations on. They are further divided into discrete (countable integers with clear boundaries) and continuous (can take any value, even decimals, within a range).\n",
        "\n",
        "**Categorical features** are columns with a limited number of possible values. Examples are `sex, country, or age group`.\n",
        "\n",
        "## Notebook overview\n",
        "\n",
        "This notebook is a guide to start practicing Data Analysis."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Title\n",
        " Impact of The COVID-19 Pandemic On Investor Funding Towards The Indian Start-up Ecosystem \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# AIM\n",
        "To investigate the impact of the Covid-19 pandemic on investor funding towards the Indian Start-up Ecosystem Using Python."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Objectives\n",
        "1. To develop a working hypothesis to investigate with analysis of dataset.\n",
        "2. To analyse and visualise the indian-startup funding dataset to come out findings.\n",
        "3. To develop recommendations for potential future investors.  \n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hypothesis\n",
        "As per the definition from Oxford languages, a hypothesis is a supposition or proposed explanation made on the basis of limited evidence as a starting point for further investigation. The hypothesis serves as the basis or motivation for developing a blue print for furthur data analyses. In other words, its directs your research and gives you an aim for your research.\n",
        "\n",
        "Developing a proper hypothesis for further investing can sometimes be a daunting task but **no need to worry!!** as there is an abundance of  **literature** on the internet concerning whatever subject area you are investigating . "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hypothesis Formed\n",
        "Indian start-up funding was severely impacted by the COVID-19 pandemic.\n",
        "\n",
        "# Alternative Hypothesis Formed\n",
        "Indian start-up funding was not severely impacted by the COVID-19 pandemic"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Research Questions Formed\n",
        "1. What was the trend of start-up funding in India before the occurence of the COVID-19 pnademic (2018-2019)?\n",
        "2. Which start-up sectors received the most funding before the pandemic?\n",
        "3. What was the trend of start-up of funding during the COVID-19 pandemic (2020-2021)?\n",
        "4. Which start-up sectors received the most funding during the COVID-19 pandemic?\n",
        "5. What was the total amount funding received each year before and after the COVID-109 pandemic?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4VFUnkuexCE"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qdFpRxPje1gw"
      },
      "source": [
        "## Installation\n",
        "Here is the section to install all the packages/libraries that will be needed to tackle the challlenge."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-d-roFQe6yi"
      },
      "outputs": [],
      "source": [
        "# !pip install -q <lib_001> <lib_002> ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HmLxlQre7HW"
      },
      "source": [
        "## Importation\n",
        "Here is the section to import all the packages/libraries that will be used through this notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MP62JaiKfCnS"
      },
      "outputs": [],
      "source": [
        "# Data handling\n",
        "import pandas as pd\n",
        "\n",
        "# Vizualisation (Matplotlib, Plotly, Seaborn, etc. )\n",
        "...\n",
        "\n",
        "# EDA (pandas-profiling, etc. )\n",
        "...\n",
        "\n",
        "# Feature Processing (Scikit-learn processing, etc. )\n",
        "...\n",
        "\n",
        "# Machine Learning (Scikit-learn Estimators, Catboost, LightGBM, etc. )\n",
        "...\n",
        "\n",
        "# Hyperparameters Fine-tuning (Scikit-learn hp search, cross-validation, etc. )\n",
        "...\n",
        "\n",
        "# Other packages\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfOADQf0e9i1"
      },
      "source": [
        "# Data Loading\n",
        "Here is the section to load the datasets (train, eval, test) and the additional files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIQyG5EcfQlU"
      },
      "outputs": [],
      "source": [
        "# For CSV, use pandas.read_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okaZxnc3fRId"
      },
      "source": [
        "# Exploratory Data Analysis: EDA\n",
        "Here is the section to **inspect** the datasets in depth, **present** it, make **hypotheses** and **think** the *cleaning, processing and features creation*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTvnZQUlD6vf"
      },
      "source": [
        "## Dataset overview\n",
        "\n",
        "Have a look at the loaded datsets using the following methods: `.head(), .info()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0VNR9LfZfbGe"
      },
      "outputs": [],
      "source": [
        "# Code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3oUlBJbRFa2t"
      },
      "outputs": [],
      "source": [
        "# Code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jp5LfsvF72x"
      },
      "source": [
        "## Univariate Analysis\n",
        "\n",
        "‘Univariate analysis’ is the analysis of one variable at a time. This analysis might be done by computing some statistical indicators and by plotting some charts respectively using the pandas dataframe's method `.describe()` and one of the plotting libraries like  [Seaborn](https://seaborn.pydata.org/), [Matplotlib](https://matplotlib.org/), [Plotly](https://seaborn.pydata.org/), etc.\n",
        "\n",
        "Please, read [this article](https://towardsdatascience.com/8-seaborn-plots-for-univariate-exploratory-data-analysis-eda-in-python-9d280b6fe67f) to know more about the charts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2MH6TKPFbBA"
      },
      "outputs": [],
      "source": [
        "# Code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TP-DiZvsWs0F"
      },
      "source": [
        "## Multivariate Analysis\n",
        "\n",
        "Multivariate analysis’ is the analysis of more than one variable and aims to study the relationships among them. This analysis might be done by computing some statistical indicators like the `correlation` and by plotting some charts.\n",
        "\n",
        "Please, read [this article](https://towardsdatascience.com/10-must-know-seaborn-functions-for-multivariate-data-analysis-in-python-7ba94847b117) to know more about the charts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NbYppWX8cfds"
      },
      "outputs": [],
      "source": [
        "# Code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pfMjvtNhlfB"
      },
      "source": [
        "# Feature processing\n",
        "Here is the section to **clean** and **process** the features of the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR_0P-SJiPx_"
      },
      "source": [
        "## Missing/NaN Values\n",
        "Handle the missing/NaN values using the Scikif-learn SimpleImputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YgaX0jfLcaK"
      },
      "outputs": [],
      "source": [
        "# Code Here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YipqthozL2kt"
      },
      "source": [
        "## Scaling\n",
        "Scale the numeric features using the Scikif-learn StandardScaler, MinMaxScaler, or another Scaler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI7jM-rZMYCG"
      },
      "outputs": [],
      "source": [
        "# Code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdFcGOxHMalr"
      },
      "source": [
        "## Encoding\n",
        "Encode the categorical features using the Scikif-learn OneHotEncoder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAMvupuRMs-P"
      },
      "outputs": [],
      "source": [
        "# Code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOzUQiPquW+CDMlvXbDiABY",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
